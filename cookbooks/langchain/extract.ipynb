{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract examples\n",
    "\n",
    "https://ai.plainenglish.io/harnessing-the-openai-api-with-langchain-and-pydantic-for-structured-data-extraction-30e3e6966699\n",
    "\n",
    "By leveraging Langchain with Pydantic, developers and businesses alike can enhance their AI-powered applications, making them more robust and efficient. The Pydantic output parser is indeed a powerful tool that unlocks new potentials for structured data extraction from LLMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"\"\"Large language models (LLMs) have demonstrated remarkable \\\n",
    "generalizability, such as understanding arbitrary entities and relations. \\\n",
    "Instruction tuning has proven effective for distilling LLMs \\\n",
    "into more cost-efficient models such as Alpaca and Vicuna. \\\n",
    "Yet such student models still trail the original LLMs by \\\n",
    "large margins in downstream applications. In this paper, \\\n",
    "we explore targeted distillation with mission-focused instruction \\\n",
    "tuning to train student models that can excel in a broad application \\\n",
    "class such as open information extraction. Using named entity \\\n",
    "recognition (NER) for case study, we show how ChatGPT can be distilled \\\n",
    "into much smaller UniversalNER models for open NER. For evaluation,\\\n",
    "we assemble the largest NER benchmark to date, comprising 43 datasets \\\n",
    "across 9 diverse domains such as biomedicine, programming, social media, \\\n",
    "law, finance. Without using any direct supervision, UniversalNER \\\n",
    "attains remarkable NER accuracy across tens of thousands of entity \\\n",
    "types, outperforming general instruction-tuned models such as Alpaca \\\n",
    "and Vicuna by over 30 absolute F1 points in average. With a tiny \\\n",
    "fraction of parameters, UniversalNER not only acquires ChatGPT's \\\n",
    "capability in recognizing arbitrary entity types, but also \\\n",
    "outperforms its NER accuracy by 7-9 absolute F1 points in average. \\\n",
    "Remarkably, UniversalNER even outperforms by a large margin \\\n",
    "state-of-the-art multi-task instruction-tuned systems such as \\\n",
    "InstructUIE, which uses supervised NER examples. \\\n",
    "We also conduct thorough ablation studies to assess the impact of \\\n",
    "various components in our distillation approach. We will release \\\n",
    "the distillation recipe, data, and UniversalNER models to facilitate \\\n",
    "future research on targeted distillation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_extraction_chain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'research_topic': 'targeted distillation with mission-focused instruction tuning', 'problem_statement': 'train student models that can excel in a broad application class such as open information extraction', 'experiment_design': 'distilling ChatGPT into smaller UniversalNER models for open NER', 'finding': 'UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average'}]\n",
      "{'research_topic': 'targeted distillation with mission-focused instruction tuning', 'problem_statement': 'train student models that can excel in a broad application class such as open information extraction', 'experiment_design': 'distilling ChatGPT into smaller UniversalNER models for open NER', 'finding': 'UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average'}\n"
     ]
    }
   ],
   "source": [
    "# Extraction using OpenAI functions\n",
    "# Schema which will be filled using extracted information\n",
    "\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"research_topic\": {\"type\": \"string\"},\n",
    "        \"problem_statement\": {\"type\": \"string\"},\n",
    "        \"experiment_design\": {\"type\": \"string\"},\n",
    "        \"finding\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"research_topic\", \"finding\"],\n",
    "}\n",
    "\n",
    "# create model\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", openai_api_key=openai.api_key)\n",
    "\n",
    "# create extraction chain \n",
    "chain = create_extraction_chain(schema, llm)\n",
    "\n",
    "#run extraction chain\n",
    "vanilla_output = chain.run(inp)\n",
    "print(vanilla_output)\n",
    "print(vanilla_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class CodeRisk(BaseModel):\n",
    "    description: str = Field(description=\"A brief description of the security risk\")\n",
    "    severity: str = Field(description=\"The level of severity of the risk\")\n",
    "    recommendations: List[str] = Field(description=\"Recommended actions to mitigate the risk\")\n",
    "\n",
    "    @field_validator(\"severity\")\n",
    "    def severity_must_be_valid(cls, v):\n",
    "        if v not in [\"Low\", \"Medium\", \"High\", \"Critical\"]:\n",
    "            raise ValueError(\"Invalid severity level!\")\n",
    "        return v\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "model_name = \"text-davinci-003\"\n",
    "temperature = 0.0\n",
    "model = OpenAI(\n",
    "  model_name=model_name,\n",
    "  temperature=temperature,\n",
    "  openai_api_key=openai.api_key,\n",
    ")\n",
    "\n",
    "code_snippet_query = \"\"\"\n",
    "Analyze the following block of code for potential security risks:\n",
    "public void authenticate(String username, String password) {\n",
    "    if (username.equals(\"admin\") && password.equals(\"password123\")) {\n",
    "    // Authentication logic\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=CodeRisk)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Identify any potential security risks in the code snippet provided.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "_input = prompt.format_prompt(query=code_snippet_query)\n",
    "output = model(_input.to_string())\n",
    "\n",
    "# The parsed_output variable now contains the structured data as a Pydantic model instance.\n",
    "parsed_output = parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description='The code snippet is vulnerable to a hard-coded credentials attack, as it checks for a specific username and password combination.' severity='High' recommendations=['Implement a secure authentication mechanism that does not rely on hard-coded credentials.', 'Ensure that passwords are stored in a secure manner, such as using a one-way hashing algorithm.']\n"
     ]
    }
   ],
   "source": [
    "print(parsed_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
