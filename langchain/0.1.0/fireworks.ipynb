{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "FIREWORKS_API_KEY = os.environ.get(\"FIREWORKS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpaz/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I like 2 of them. One of the 2 is Elton John. Who is the third musician?\\n\\nA: You like 2 of the 3 musicians. You like Elton John, and you like 1 other of the 3 musicians. You don't necessarily like the 3rd musician, but he is one of the 3 musicians referred to, so he is the answer. The answer is also the musician who you are not sure if you like, but who is one of the 3 musicians being considered. That is, the third musician has not been ruled out as one of the musicians who you like. So, the third musician is NOT someone who you don't like. The third musician is the one who you are not sure if you like or not. That is, the third musician is the one who you are considering the possibility of liking, and he is not ruled out as one of the musicians who you like.\\n\\nA: The third musician is the one who you are uncertain whether or not you like. He has not been ruled out, and you have not stated that you do not like him.\\n\\nA: The third musician being considered is a musician who you are not sure if you\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_fireworks import Fireworks \n",
    "\n",
    "llm = Fireworks(\n",
    "    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "    max_tokens=256)\n",
    "\n",
    "llm(\"Name 3 musicians.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'm here to help you with any questions or tasks you may have. Please feel free to ask me anything, and I will do my best to assist you in a safe and respectful manner. Is there anything specific you would like to know or discuss?\n"
     ]
    }
   ],
   "source": [
    "from fireworks.client import Fireworks\n",
    "\n",
    "client = Fireworks(api_key=FIREWORKS_API_KEY)\n",
    "response = client.chat.completions.create(\n",
    "  model=\"accounts/fireworks/models/llama-v2-7b-chat\",\n",
    "  messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Say this is a test\",\n",
    "  }],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'm here to help you with any questions or tasks you may have. Please feel free to ask me anything, and I will do my best to assist you in a safe, respectful, and socially unbiased manner. Is there anything specific you would like to know or discuss?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=FIREWORKS_API_KEY,\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "  model=\"accounts/fireworks/models/llama-v2-7b-chat\",\n",
    "  messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Say this is a test\",\n",
    "  }],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
