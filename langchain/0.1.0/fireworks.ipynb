{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "FIREWORKS_API_KEY = os.environ.get(\"FIREWORKS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpaz/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' A: “Is your favorite instrument in an orchestra a stringed instrument?”\\nB: “Yes it is, and I’m sure the other two of you will also say yes.”\\nC: “I’m not going to answer this question.”\\nA: “Then at least tell us whether you play a stringed instrument or not.”\\nC: “I’m not going to answer this question either.”\\n\\nB: “Could it be that our third friend here plays the drums?”\\nA: (smiling) “I don’t know whether he does or not. But if he does, then he certainly wouldn’t be the first person to try to hide it!”\\n\\nC: “OK, I confess, I’m the one who plays the drums.”\\nJustify:\\nC plays the drums, and the other two do not play any stringed instruments.\\n\\n1. A guesses that C plays the drums. This eliminates “No” as B’s possible answer.\\n2. Then A can no longer be talking about playing the drums when he says, “But if he does, then he certainly wouldn’t be the first person to try to hide it!” (because C has'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_fireworks import Fireworks \n",
    "\n",
    "llm = Fireworks(\n",
    "    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "    max_tokens=256)\n",
    "\n",
    "llm(\"Name 3 musicians.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'm here to assist you in a safe and respectful manner. Please feel free to ask me any question you have, and I will do my best to provide a helpful and informative response while ensuring that my answer is socially unbiased and positive in nature. Is there anything specific you would like to know or discuss?\n"
     ]
    }
   ],
   "source": [
    "from fireworks.client import Fireworks\n",
    "\n",
    "client = Fireworks(api_key=FIREWORKS_API_KEY)\n",
    "response = client.chat.completions.create(\n",
    "  model=\"accounts/fireworks/models/llama-v2-7b-chat\",\n",
    "  messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Say this is a test\",\n",
    "  }],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'm happy to help you with your test. Please provide me with more details or information about the test, such as the type of test, the subject matter, or any specific questions you may have, and I will do my best to assist you in a safe and respectful manner.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=FIREWORKS_API_KEY,\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "  model=\"accounts/fireworks/models/llama-v2-7b-chat\",\n",
    "  messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Say this is a test\",\n",
    "  }],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
